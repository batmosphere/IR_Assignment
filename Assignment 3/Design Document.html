<!doctype html>
<html><head><title>Design Document</title><meta charset="UTF-8"><link type="text/css" rel="stylesheet" href="http://fonts.googleapis.com/css?family=Crimson+Text:400,400italic,700,700italic|Roboto:400,700,700italic,400italic"><style>

body {
    font-size: 15px;
    color: #333;
    background: #fff;
    padding: 60px 95px;
    max-width: 900px;
    margin: 0 auto;
    text-rendering: optimizeLegibility;
    font-feature-settings: "kern";
    font-kerning: normal;
    -moz-font-feature-settings: "kern";
    -webkit-font-feature-settings: "kern";
}

/* Headings */
h1, h2, h3, th {
    font-family: Roboto, sans-serif;
    font-weight: 700;
    margin: 0;
    margin-top: 1.25em;
    margin-bottom: 0.75em;
}

h1 {
    font-size: 35px;
    line-height: 42px;
}

h1:first-child {
    margin-top: 0;
}

h2 {
    font-size: 18px;
    line-height: 22px;
}

h3 {
    text-transform: uppercase;
    font-size: 13px;
    line-height: 16px;
}

/* Body text */
body, p, ul, ol, td {
    font-family: 'Crimson Text', serif;
    font-size: 16px;
    line-height: 20px;
}

blockquote, q {
    display: block;
    margin: 1em 0;
    font-style: italic;
}

blockquote a, q a {
    text-decoration: underline;
}

blockquote {
    padding-left: 10px;
    border-left: 4px solid #a6a6a6;
}

q {
    color: #a6a6a6;
    line-height: 40px;
    font-size: 24px;
    text-align: center;
    quotes: none;
}

q a {
    color: #a6a6a6;
}

code, pre {
    font-family: Consolas, "Liberation Mono", Menlo, "Courier Prime Web", Courier, monospace;
    background: #f3f3f3;
}

code {
    padding: 1px;
    margin: 0 -1px;
    border-radius: 3px;
}

pre {
    display: block;
    line-height: 20px;
    text-shadow: 0 1px white;
    padding: 5px 5px 5px 30px;
    white-space: nowrap;
    position: relative;
    margin: 1em 0;
}

pre:before {
    content: "";
    position: absolute;
    top: 0;
    bottom: 0;
    left: 15px;
    border-left: solid 1px #dadada;
}

/* Lists */
div[data-section-style="5"],
div[data-section-style="6"],
div[data-section-style="7"] {
    margin: 12px 0;
}

ul {
    padding: 0 0 0 40px;
}

ul li {
    margin-bottom: 0.4em;
}

/* Bulleted list */
div[data-section-style="5"] ul {
    list-style-type: disc;
}
div[data-section-style="5"] ul ul {
    list-style-type: circle;
}
div[data-section-style="5"] ul ul ul {
    list-style-type: square;
}
div[data-section-style="5"] ul ul ul ul {
    list-style-type: disc;
}
div[data-section-style="5"] ul ul ul ul ul {
    list-style-type: circle;
}
div[data-section-style="5"] ul ul ul ul ul ul {
    list-style-type: square;
}

/* Numbered list */
div[data-section-style="6"] ul {
    list-style-type: decimal;
}
div[data-section-style="6"] ul ul {
    list-style-type: lower-alpha;
}
div[data-section-style="6"] ul ul ul {
    list-style-type: lower-roman;
}
div[data-section-style="6"] ul ul ul ul {
    list-style-type: decimal;
}
div[data-section-style="6"] ul ul ul ul ul {
    list-style-type: lower-alpha;
}
div[data-section-style="6"] ul ul ul ul ul ul {
    list-style-type: lower-roman;
}

/* Checklist */
div[data-section-style="7"] ul {
    list-style-type: none;
}

div[data-section-style="7"] ul li:before {
    content: "\2610";
    position: absolute;
    display: inline;
    margin-right: 1.2em;
    margin-left: -1.2em;
}

div[data-section-style="7"] ul li.parent:before {
    content: "";
}

div[data-section-style="7"] ul li.parent {
    font-weight: bold;
}

div[data-section-style="7"] ul li.checked {
    text-decoration: line-through;
}

div[data-section-style="7"] ul li.checked:before {
    content: "\2611";
    text-decoration: none;
}

/* Tables */
div[data-section-style="8"] {
    margin: 12px 0;
}

table {
    border-spacing: 0;
    border-collapse: separate;
    border: solid 1px #7c7c7c;
    box-shadow: 0 1px 2px rgba(0, 0, 0, .25);
    table-layout: fixed;
    position: relative;
}

table th, table td {
    padding: 2px 2px 0;
    min-width: 1.5em;
    word-wrap: break-word;
}

table th {
    border-bottom: 1px solid #ccc;
    background: #f0f0f0;
    font-weight: bold;
    vertical-align: bottom;
    color: #3a4449;
    text-align: center;
}

table td {
    padding-top: 0;
    border-left: 1px solid #e1e1e1;
    border-top: 1px solid #e1e1e1;
    vertical-align: top;
}

table td.bold {
    font-weight: bold;
}

table td.italic {
    font-style: italic;
}

table td.underline {
    text-decoration: underline;
}

table td.strikethrough {
    text-decoration: line-through;
}

table td.underline.strikethrough {
    text-decoration: underline line-through;
}

table td:first-child {
    border-left: hidden;
}

table tr:first-child td {
    border-top: hidden;
}

/* Images */
div[data-section-style="11"] {
    margin-top: 20px;
    margin-bottom: 20px;
    margin-left: auto;
    margin-right: auto;
}

div[data-section-style="11"][data-section-float="0"] {
    clear: both;
    text-align: center;
}

div[data-section-style="11"][data-section-float="1"] {
    float: left;
    clear: left;
    margin-right: 20px;
}

div[data-section-style="11"][data-section-float="2"] {
    float: right;
    clear: right;
    margin-left: 20px;
}

div[data-section-style="11"] img {
    display: block;
    max-width: 100%;
    height: auto;
    margin: auto;
}

hr {
    width: 70px;
    margin: 20px auto;
}
</style></head><body><h1 id='DWXACAoq696'>Design Document</h1>

<h2 id='DWXACA42Qhw'>Introduction</h2>

<h3 id='DWXACAui6pU'>the assignment:</h3>

This Assignment has been worked on by members of the team, on<b> Dimensional Reduction methods for Recommender Systems</b>, using two different dimensional reduction methods-<b> SVD </b>and <b>CUR</b>. <br/>

<br/>

The purpose of this design document is to explore the details of the ideas behind the code-about SVD and CUR<br/>

 and how the software works as an implementation of Recommender System. We have chosen to code the dimensional methods of SVD and CUR for the data set pertaining to the data set “MovieLens”, provided by the GroupLens Reseach association from the MovieLens website. This data was collected over a period of time, with about 100000 ratings provided for 9000 movies by 700 users with about 1300 tag applications.<br/>

<h3 id='DWXACAkNkZI'>recommender systems- A brief intro</h3>

There are various web-based applications that enable one to choose from a variety of products or items based on the predictions made using the user's previously chosen options and options of other users. These are known as Recommender Systems.<br/>

There are different kinds of Recommender System, which can be broadly based into two different categories:<br/>

<div data-section-style='5'><ul id='DWXACAmVEjp'><li id='DWXACAh9gyi' class='' value='1'><b>Content Based Systems</b>

<br/></li><li id='DWXACA7vdy7' class=''><b>Collaborative Filtering Systems</b>

<br/></li></ul></div>Here we will look into the Collaborative Filtering System- and the decompostion methods in particular.<br/>

<hr/><h3 id='DWXACAZNYd9'>Dimensional reduction:</h3>

Manifold learning is a significant problem across a wide variety of information processing fields including pattern recognition, data compression, machine learning, and database navigation. In many problems, the measured data vectors are high-dimensional.<br/>

<br/>

may have reason to believe that the data lie near a lower-dimensional manifoldLearning a suitable low-dimensional manifold from high-dimensional data is essentially the same as learning<br/>

<q id='DWXACAkB8nP'><b>Dimensionality reduction can also be seen as the process of deriving a set of degrees of freedom which can be used to reproduce most of the variability of a data set.</b></q>

<br/>

 Consider a set of images produced by the rotation of a face through different angles. Clearly only one degree of freedom is being altered, and thus the images lie along a continuous one-dimensional curve through image space.<br/>

<h2 id='DWXACAIQlk4'>SVD - Singular Value Decomposition</h2>

The singular value decomposition (SVD) is a generalization of the eigen decomposition which can be used to analyze rectangular matrices (the eigen decomposition is defined only for squared matrices). By analogy with the eigen-decomposition, which decomposes a matrix into two simple matrices.<br/>

<br/>

The main idea of SVD is to decompose the given matrix into three different matrices. These three matrices are:<br/>

2 Orthogonal Matrices - U and V^T (transpose of V)<br/>

1 Diagonal Matrix          -  Sigma / K<br/>

<br/>

 This matrix is obviously square and symmetric, but also (and this is less obvious) its eigenvalues<br/>

are all positive or null, and the eigenvectors corresponding to different eigenvalues are pairwise orthogonal.<br/>

<br/>

Formally, if  A is a rectangular matrix, SVD decomposition occurs as <br/>

<pre id='DWXACAhpu2k'>A = UKV^T</pre>

with:<br/>

<b>A </b>→(<b>mxn</b> matrix) <br/>

<b>U</b> → <b>(mxr</b> matrix)the normalized eigen vectors of the matrix AA^T, the columns of U are called left-singular vectors of A.<br/>

<b>V</b> →(<b>nxr </b>matrix)  the normalized eigen  vactors of the matrix A^T A, the columns of V are called right-singular vectors of A.<br/>

<b>K</b> →(<b>rxr</b> matrix) the diagonal matrix of the singular values, K = L^1/2 where L being the diagonal matrix of the eigen values of the matrix AA^T and A^TA<br/>

<h3 id='DWXACABl6uH'>SVD - Properties:</h3>

It is possible to decompose the matrix into the above mentioned three matrices, such that<br/>

<div data-section-style='6'><ul id='DWXACAPwMWT'><li id='DWXACA0i2Nv' class='' value='1'>All three are unique

<br/></li><li id='DWXACAk5DIc' class=''>U and V are column orthogonal and dense

<br/></li><li id='DWXACA3Q0t7' class=''>K is diagonal and sparse, such that the entries are positive and are sorted in a decreasing order.

<br/></li></ul></div><h2 id='DWXACA2aJbp'>CUR Decomposition:</h2>

It is a low-rank approximation explicitly expressed in terms of a small number of columns and rows of the original matrix A:<br/>

<pre id='DWXACAWC9we'>A = C U R</pre>

Here,<br/>

A →the matrix (mxn)<br/>

C →is made from the columns of A (mxr)<br/>

R →matrix taken from the rows of A (rxn)<br/>

U →An rxr matrix, that is calculated using the SVD technique.<br/>

<br/>

There are certain drawbacks with using SVD as a dimensional reduction technique, which can be improved using CUR:<br/>

<div data-section-style='5'><ul id='DWXACABHjjy'><li id='DWXACAAAeC0' class='' value='1'><b>More Time: </b>SVD takes more time to process, and while SVD guarantees optimality, time is of the essence

<br/></li><li id='DWXACAA6uzy' class=''><b>More Computational Cost: </b>SVD while optimal, here we can decrease the computational cost, while allowing for an increase in error.

<br/></li></ul></div><h3 id='DWXACA3GrcO'>CUR - properties:</h3>

<div data-section-style='6'><ul id='DWXACArVCID'><li id='DWXACAdX6N6' class='' value='1'><b>Easy to Interpret</b>

<br/></li><li id='DWXACAj5CTK' class=''><b>Sparse Basis Vectors of Matrix</b>

<br/></li><li id='DWXACAc7ODQ' class=''><b>Duplicate columns and rows </b>

<br/></li></ul></div>Here U is a matrix that is constructed by a pseudo-inverse of the intersection of the chosen rows and columns from the matrix A.<br/>

<hr/><h2 id='DWXACAzxU60'>Conclusion:</h2>

In our understanding of CUR and SVD, we come across the fact that the reconsrtuction error of CUR is less than or equal to that of SVD plus some (epsilon) times of the Frobinius norm of A. Also, it can be noted that it takes less time to process the code for CUR in comparision for SVD.<br/>

<br/>

While it can be argued that either of SVD or CUR are better or not, we have chosen to provide implementations of both in our software. <br/>

</body></html>